{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This code collects the time resolved optical properties of Ta2NiSe5 as calculated from the equilibrium properties and time-resolved pump-probe optical spectroscopy, creates dataframes containing both the equilibrium and time-resolved data, and saves the resulting dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy\n",
    "import math\n",
    "from scipy.signal import savgol_filter,boxcar\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "\n",
    "h = 6.62e-34 #Planck's constant\n",
    "c = 3e8      #Speed of light\n",
    "e = 1.6e-19  #Charge of the electron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectchars(x,Ref=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to select parts \n",
    "    of file names for the \n",
    "    purpose of labeling graphs.\n",
    "    \"\"\"\n",
    "    \n",
    "    if Ref:\n",
    "        return(int(x[3:-6]))\n",
    "    else:\n",
    "        return(int(x[4:-6]))\n",
    "\n",
    "\n",
    "def get_all_txt_names(folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate list of all required filenames\n",
    "    \"\"\"\n",
    "    \n",
    "    TFolder_R = os.path.join(folder,\"dR\")\n",
    "    T_files_R = sorted([f for f in os.listdir(TFolder_R) if f.endswith(\".txt\")],\n",
    "                         key=lambda f:selectchars(f,Ref=True))\n",
    "    \n",
    "    TFolder_S1 = os.path.join(folder,\"dS1\")\n",
    "    T_files_S1 = sorted([f for f in os.listdir(TFolder_S1) if f.endswith(\".txt\")],\n",
    "                         key=lambda f:selectchars(f,Ref=False))\n",
    "    \n",
    "    TFolder_S2 = os.path.join(folder,\"dS2\")\n",
    "    T_files_S2 = sorted([f for f in os.listdir(TFolder_S2) if f.endswith(\".txt\")],\n",
    "                         key=lambda f:selectchars(f,Ref=False))\n",
    "    \n",
    "    return T_files_R, T_files_S1, T_files_S2\n",
    "\n",
    "def convert_to_wl(WN):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert wavenumbers to wavelenghts\n",
    "    \"\"\"\n",
    "    \n",
    "    wl = (10**7)/(WN)    \n",
    "    return wl\n",
    "\n",
    "def convert_to_En(wl):\n",
    "    \n",
    "    \"\"\"\n",
    "    Convert wavelength to energy\n",
    "    \"\"\"\n",
    "    \n",
    "    h = 6.62e-34\n",
    "    c = 3e8\n",
    "    e = 1.6e-19\n",
    "    En = (h*c*10**9)/(e*wl)\n",
    "    return En\n",
    "\n",
    "\n",
    "def interp_stat_data(df,WN):\n",
    "    \"\"\"\n",
    "    Interpolate the static data\n",
    "    in the wavenumber of regions \n",
    "    where no data points were collected.\n",
    "    \"\"\"\n",
    "    \n",
    "    intfit=interp1d(df.iloc[:,0],df.iloc[:,1])\n",
    "    data_array = intfit(WN.values)\n",
    "    \n",
    "    return pd.Series(data_array,name=\"stat\")\n",
    "\n",
    "\n",
    "\n",
    "def create_time_df(folder,files,stat_file,prop=\"dR\"):\n",
    "    \"\"\"\n",
    "    Create dataframe with equilibrium data and \n",
    "    a sequence of time steps.\n",
    "    \"\"\"\n",
    "    \n",
    "    sep = \" \" \n",
    "    \n",
    "    if prop == \"dR\":\n",
    "        Ref = True\n",
    "    else:\n",
    "        Ref = False\n",
    "        \n",
    "    df = pd.read_csv(os.path.join(folder,prop,files[0]),sep=sep,header=None,names=[\"WN\",\"temp\"],dtype='float32')\n",
    "    df.drop(\"temp\",axis=1,inplace=True)\n",
    "    df[\"WN\"] = df[\"WN\"].apply(float)\n",
    "    df[\"WL\"] = df[\"WN\"].apply(convert_to_wl)\n",
    "    df[\"En\"] = df[\"WL\"].apply(convert_to_En)\n",
    "    \n",
    "    stat = pd.read_csv(stat_file, sep=\",\",header=None,names=[\"WN\",prop]) \n",
    "    df[\"stat\"] = interp_stat_data(stat,df[\"WN\"])\n",
    "    \n",
    "    for f in files:\n",
    "        \n",
    "        tempdf = pd.read_csv(os.path.join(folder,prop,f),sep=sep,header=None,names=[\"WN\",selectchars(f,Ref=Ref)],\n",
    "                            dtype='float32')\n",
    "        tempdf[selectchars(f,Ref=Ref)] = tempdf[selectchars(f,Ref=Ref)]+df[\"stat\"]\n",
    "        df = pd.merge(df,tempdf,on=\"WN\",how=\"inner\")\n",
    "        \n",
    "    return df     \n",
    "\n",
    "\n",
    "def check_df_size(folder,prop=\"dR\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Quickly check data folder sizes.\n",
    "    Used in the troubleshooting process.\n",
    "    \"\"\"\n",
    "    \n",
    "    sep = \" \" \n",
    "    \n",
    "    if prop == \"dR\":\n",
    "        Ref = True\n",
    "    else:\n",
    "        Ref = False\n",
    "    \n",
    "    TFolder = os.path.join(folder,prop)\n",
    "    files = sorted([f for f in os.listdir(TFolder) if f.endswith(\".txt\")],\n",
    "                         key=lambda f:selectchars(f,Ref=Ref))\n",
    "    \n",
    "    Size = []\n",
    "\n",
    "    sep = \" \" \n",
    "    \n",
    "    for f in files:\n",
    "        df = pd.read_csv(os.path.join(TFolder,f),sep=\" \",header=None,names=[\"WN\",\"temp\"],\n",
    "                            dtype='float32')\n",
    "        Size.append(df.shape)\n",
    "        \n",
    "    return Size \n",
    "    \n",
    "\n",
    "def create_all_df(folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create all required dataframes using only \n",
    "    the fit to the data\n",
    "    \"\"\"\n",
    "    \n",
    "    R_stat_file = os.path.abspath(os.path.join(folder,os.pardir)) + \"\\R.csv\"\n",
    "    S1_stat_file = os.path.abspath(os.path.join(folder,os.pardir)) + \"\\S1_fit.csv\"\n",
    "    S2_stat_file = os.path.abspath(os.path.join(folder,os.pardir)) + \"\\S2_fit.csv\"\n",
    "    \n",
    "    TimeRFiles,TimeS1Files,TimeS2Files = get_all_txt_names(folder)\n",
    "    R_df = create_time_df(folder,TimeRFiles,R_stat_file)\n",
    "    S1_df = create_time_df(folder,TimeS1Files,S1_stat_file,prop=\"dS1\")\n",
    "    S2_df = create_time_df(folder,TimeS2Files,S2_stat_file,prop=\"dS2\")\n",
    "    \n",
    "    return R_df, S1_df, S2_df\n",
    "\n",
    "\n",
    "def create_all_df_rawAndfit(folder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create all required dataframes including \n",
    "    both the raw data and the fits. \n",
    "    \"\"\"\n",
    "    \n",
    "    R_stat_file = os.path.abspath(os.path.join(folder,os.pardir)) + \"\\R.csv\"\n",
    "    S1raw_stat_file = os.path.abspath(os.path.join(folder,os.pardir)) + \"\\S1_raw.csv\"\n",
    "    S1fit_stat_file = os.path.abspath(os.path.join(folder,os.pardir)) + \"\\S1_fit.csv\"\n",
    "    S2raw_stat_file = os.path.abspath(os.path.join(folder,os.pardir)) + \"\\S2_raw.csv\"\n",
    "    S2fit_stat_file = os.path.abspath(os.path.join(folder,os.pardir)) + \"\\S2_fit.csv\"\n",
    "    \n",
    "    TimeRFiles,TimeS1Files,TimeS2Files = get_all_txt_names(folder)\n",
    "    R_df = create_time_df(folder,TimeRFiles,R_stat_file)\n",
    "    S1raw_df = create_time_df(folder,TimeS1Files,S1raw_stat_file,prop=\"dS1\")\n",
    "    S1fit_df = create_time_df(folder,TimeS1Files,S1fit_stat_file,prop=\"dS1\")\n",
    "    S2raw_df = create_time_df(folder,TimeS2Files,S2raw_stat_file,prop=\"dS2\")\n",
    "    S2fit_df = create_time_df(folder,TimeS2Files,S2fit_stat_file,prop=\"dS2\")\n",
    "    \n",
    "    return R_df, S1raw_df, S1fit_df, S2raw_df, S2fit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static data at Room Temperature\n",
    "RT150fld = '../data/Unprocessed/RT/150uW/'\n",
    "RT900fld = '../data/Unprocessed/RT/900uW/'\n",
    "RT3500fld = '../data/Unprocessed/RT/3500uW/'\n",
    "RT4000fld = '../data/Unprocessed/RT/4000uW/'\n",
    "RT5000fld = '../data/Unprocessed/RT/5000uW/'\n",
    "RT6000fld = '../data/Unprocessed/RT/6000uW/'\n",
    "\n",
    "# Static data at 345 K\n",
    "HT250fld = '../data/Unprocessed/HT/250uW/'\n",
    "HT3000fld = '../data/Unprocessed/HT/3000uW/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2), (1000, 2)]\n"
     ]
    }
   ],
   "source": [
    "size = check_df_size(HT3000fld,\"dS1\")\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct dataframes with static and time resolved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare using raw or fit as static data\n",
    "\n",
    "RT150_R, RT150_S1raw, RT150_S1fit, RT150_S2raw, RT150_S2fit = create_all_df_rawAndfit(RT150fld)\n",
    "RT900_R, RT900_S1raw, RT900_S1fit, RT900_S2raw, RT900_S2fit = create_all_df_rawAndfit(RT900fld)\n",
    "RT3500_R, RT3500_S1raw, RT3500_S1fit, RT3500_S2raw, RT3500_S2fit = create_all_df_rawAndfit(RT3500fld)\n",
    "RT4000_R, RT4000_S1raw, RT4000_S1fit, RT4000_S2raw, RT4000_S2fit = create_all_df_rawAndfit(RT4000fld)\n",
    "RT5000_R, RT5000_S1raw, RT5000_S1fit, RT5000_S2raw, RT5000_S2fit = create_all_df_rawAndfit(RT5000fld)\n",
    "RT6000_R, RT6000_S1raw, RT6000_S1fit, RT6000_S2raw, RT6000_S2fit = create_all_df_rawAndfit(RT6000fld)\n",
    "\n",
    "HT250_R, HT250_S1raw, HT250_S1fit, HT250_S2raw, HT250_S2fit = create_all_df_rawAndfit(HT250fld)\n",
    "HT3000_R, HT3000_S1raw, HT3000_S1fit, HT3000_S2raw, HT3000_S2fit = create_all_df_rawAndfit(HT3000fld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT150_S1fit.to_csv('../data/Dataframes/RT150_S1.csv', index=False)\n",
    "RT900_S1fit.to_csv('../data/Dataframes/RT900_S1.csv', index=False)\n",
    "RT3500_S1fit.to_csv('../data/Dataframes/RT3500_S1.csv', index=False)\n",
    "RT4000_S1fit.to_csv('../data/Dataframes/RT4000_S1.csv', index=False)\n",
    "RT5000_S1fit.to_csv('../data/Dataframes/RT5000_S1.csv', index=False)\n",
    "RT6000_S1fit.to_csv('../data/Dataframes/RT6000_S1.csv', index=False)\n",
    "\n",
    "HT250_S1fit.to_csv('../data/Dataframes/HT250_S1.csv', index=False)\n",
    "HT3000_S1fit.to_csv('../data/Dataframes/HT3000_S1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
